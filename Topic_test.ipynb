{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "from CTMClass import CTMClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/ky/抗疫1-4月.xlsx\"\n",
    "dict = \"data/words_all.txt\"\n",
    "stop_dict = \"data/stop_words_all.txt\"\n",
    "log_file = open('logs/log_ctm_ONE_allstop14new.txt', mode = 'a',encoding='utf-8')\n",
    "file_model = 'models/_all_stopone'\n",
    "rm_top = 0\n",
    "cf = 0\n",
    "df = 0\n",
    "tw = tp.TermWeight.ONE\n",
    "k = 1\n",
    "iter = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctm_model = CTMClass(file, file_model, k, dict, stop_dict, iter, log_file, tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctm_model.TrainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "from PAMClass import PAMClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/数据汇总（2020年疫情防控-人民日报）.xlsx\"\n",
    "dict = \"data/words_all.txt\"\n",
    "stop_dict = \"data/stop_words_all.txt\"\n",
    "log_file = open('logs/log_pam_ONE_allstop14new.txt', mode = 'a',encoding='utf-8')\n",
    "file_model = 'models/_all_stopone'\n",
    "rm_top = 0\n",
    "cf = 0\n",
    "df = 0\n",
    "tw = tp.TermWeight.ONE\n",
    "k = 1\n",
    "iter = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAMClass = PAMClass(file, file_model, k, dict, stop_dict, iter, log_file, tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs:2123, Num Vocabs:57185, Total Words:745092\n",
      "Iteration: 0000, LL per word: -14.37\n",
      "Iteration: 0020, LL per word: -11.59\n",
      "Iteration: 0040, LL per word: -11.33\n",
      "Iteration: 0060, LL per word: -11.25\n",
      "Iteration: 0080, LL per word: -11.2\n",
      "Iteration: 0100, LL per word: -11.17\n",
      "Iteration: 0120, LL per word: -11.16\n",
      "Iteration: 0140, LL per word: -11.14\n",
      "Iteration: 0160, LL per word: -11.14\n",
      "Iteration: 0180, LL per word: -11.13\n",
      "Iteration: 0200, LL per word: -11.12\n",
      "Iteration: 0220, LL per word: -11.12\n",
      "Iteration: 0240, LL per word: -11.11\n",
      "Iteration: 0260, LL per word: -11.11\n",
      "Iteration: 0280, LL per word: -11.11\n",
      "Iteration: 0300, LL per word: -11.1\n",
      "Iteration: 0320, LL per word: -11.1\n",
      "Iteration: 0340, LL per word: -11.09\n",
      "Iteration: 0360, LL per word: -11.09\n",
      "Iteration: 0380, LL per word: -11.09\n",
      "Iteration: 0400, LL per word: -11.08\n",
      "Iteration: 0420, LL per word: -11.08\n",
      "Iteration: 0440, LL per word: -11.08\n",
      "Iteration: 0460, LL per word: -11.07\n",
      "Iteration: 0480, LL per word: -11.07\n",
      "Iteration: 0500, LL per word: -11.07\n",
      "Iteration: 0520, LL per word: -11.06\n",
      "Iteration: 0540, LL per word: -11.05\n",
      "Iteration: 0560, LL per word: -11.05\n",
      "Iteration: 0580, LL per word: -11.05\n",
      "Iteration: 0600, LL per word: -11.04\n",
      "Iteration: 0620, LL per word: -11.04\n",
      "Iteration: 0640, LL per word: -11.04\n",
      "Iteration: 0660, LL per word: -11.04\n",
      "Iteration: 0680, LL per word: -11.04\n",
      "Iteration: 0700, LL per word: -11.04\n",
      "Iteration: 0720, LL per word: -11.03\n",
      "Iteration: 0740, LL per word: -11.04\n",
      "Iteration: 0760, LL per word: -11.04\n",
      "Iteration: 0780, LL per word: -11.03\n",
      "Iteration: 0800, LL per word: -11.03\n",
      "Iteration: 0820, LL per word: -11.03\n",
      "Iteration: 0840, LL per word: -11.03\n",
      "Iteration: 0860, LL per word: -11.02\n",
      "Iteration: 0880, LL per word: -11.02\n",
      "Iteration: 0900, LL per word: -11.02\n",
      "Iteration: 0920, LL per word: -11.03\n",
      "Iteration: 0940, LL per word: -11.03\n",
      "Iteration: 0960, LL per word: -11.02\n",
      "Iteration: 0980, LL per word: -11.03\n",
      "Iteration: 1000, LL per word: -11.01\n",
      "<Basic Info>\n",
      "| PAModel (current version: 0.12.1)\n",
      "| 2123 docs, 745092 words\n",
      "| Total Vocabs: 57185, Used Vocabs: 57185\n",
      "| Entropy of words: 8.84624\n",
      "| Entropy of term-weighted words: 8.84624\n",
      "| Removed Vocabs: <NA>\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 1000, Burn-in steps: 0\n",
      "| Optimization Interval: 1\n",
      "| Log-likelihood per word: -11.01303\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 0 (the number of top words to be removed)\n",
      "| k1: 5 (the number of super topics between 1 ~ 32767)\n",
      "| k2: 20 (the number of sub topics between 1 ~ 32767)\n",
      "| alpha: [0.1] (initial hyperparameter of Dirichlet distribution for document-super topic, given as a single `float` in case of symmetric prior and as a list with length `k1` of `float` in case of asymmetric prior.)\n",
      "| subalpha: [0.1] (initial hyperparameter of Dirichlet distribution for super-sub topic, given as a single `float` in case of symmetric prior and as a list with length `k2` of `float` in case of asymmetric prior.)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for sub topic-word)\n",
      "| seed: 306879656 (random seed)\n",
      "| trained in version 0.12.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document super topic distributions)\n",
      "|  [0.1 0.1 0.1 0.1 0.1]\n",
      "| subalpha (Dirichlet prior on the sub topic distributions for each super topic)\n",
      "|  Super #0: [0.04052915 0.01855544 0.04898241 0.0444772  0.03638558 0.02622074\n",
      "|    0.02642054 0.05217327 0.04137641 0.00903571 0.01791694 0.0187945\n",
      "|    0.05171329 0.05641447 0.0429864  0.0635475  0.06248384 0.03625865\n",
      "|    0.04292719 0.05159187]\n",
      "|  Super #1: [0.04880185 0.01725756 0.02010554 0.02735093 0.02888289 0.02330335\n",
      "|    0.01740516 0.06228303 0.0363549  0.00562319 0.01856572 0.01248109\n",
      "|    0.04373011 0.04786659 0.0709226  0.04936963 0.04736374 0.02909598\n",
      "|    0.04664807 0.05763883]\n",
      "|  Super #2: [0.06467357 0.02964845 0.02990991 0.04200917 0.04185103 0.02815248\n",
      "|    0.01471036 0.06319732 0.04637507 0.00859976 0.03150367 0.0095984\n",
      "|    0.0649934  0.06534702 0.06064713 0.07132847 0.04146787 0.06368065\n",
      "|    0.06954606 0.07442121]\n",
      "|  Super #3: [0.04497544 0.04041231 0.04069226 0.03669845 0.06726955 0.0427886\n",
      "|    0.02961214 0.05108104 0.09247765 0.01233402 0.0223108  0.00924086\n",
      "|    0.08162072 0.04535807 0.04877858 0.08681066 0.06788429 0.03409635\n",
      "|    0.0883784  0.06364254]\n",
      "|  Super #4: [0.04608999 0.01941274 0.02524125 0.05093322 0.1194979  0.04760955\n",
      "|    0.03085846 0.06831943 0.10182235 0.0104572  0.03329044 0.01542824\n",
      "|    0.06507866 0.04751954 0.0652052  0.07213078 0.03011448 0.04201575\n",
      "|    0.07152632 0.03895289]\n",
      "| eta (Dirichlet prior on the per-subtopic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| Sub-topic distribution of Super-topics\n",
      "|  #Super0 (150339) : #7 #15 #16 #18 #11 #14 #12 #13 #2 #19 #5 #4 #8 #3 #6 #0 #17 #1 #9 #10\n",
      "|  #Super1 (143192) : #14 #7 #19 #16 #18 #0 #13 #12 #15 #17 #11 #4 #10 #8 #3 #5 #2 #6 #1 #9\n",
      "|  #Super2 (162992) : #18 #7 #15 #14 #19 #0 #17 #13 #12 #4 #16 #11 #5 #3 #8 #2 #10 #1 #9 #6\n",
      "|  #Super3 (144276) : #18 #16 #12 #14 #15 #8 #7 #4 #19 #13 #0 #5 #1 #2 #17 #3 #10 #6 #9 #11\n",
      "|  #Super4 (144293) : #4 #18 #7 #14 #8 #0 #5 #12 #15 #17 #13 #10 #19 #16 #3 #6 #2 #1 #9 #11\n",
      "| Word distribution of Sub-topics\n",
      "|  #0 (40299) : 国家 力量 生命 中华民族 强大 制度 历史 斗争 中国共产党 新冠肺炎 抗疫斗争 抗击疫情 展现 优势 抗击 担当 民族 抗疫 彰显 团结\n",
      "|  #1 (17960) : 疫情防控 依法 法治 法律 野生动物 保障 传染病 措施 监督 健康 公共卫生 执法 信息 群众 国家 建议 防疫 规范 法律法规 司法\n",
      "|  #2 (27383) : 疫苗 病毒 中医 新冠肺炎 科研 中医药 临床 国家 研发 研究 新冠 药物 治疗 技术 疫苗研发 科学 科技 攻关 中药 临床试验\n",
      "|  #3 (26748) : 学生 文化 学习 媒体 平台 网络 志愿者 抗疫 学校 在线 心理 生活 民众 孩子 教学 教育 传递 线上 大学 信息\n",
      "|  #4 (44444) : 经济 发展 企业 恢复 冲击 复工复产 消费 稳定 经济社会 生产 供应链 投资 政策 产业链 需求 创新 健康 行业 能力 服务\n",
      "|  #5 (33786) : 企业 就业 政策 保障 资金 复工复产 贷款 疫情防控 农业 服务 生产 脱贫攻坚 重点 扶贫 困难 复工 农产品 专项 脱贫 返岗\n",
      "|  #6 (20439) : 项目 员工 企业 防疫 泰国 施工 班列 铁路 中欧 工人 一带一路 技术 工程 保障 现场 生产 通道 电站 共建 合作\n",
      "|  #7 (60394) : 抗疫 物资 中方 抗击疫情 中国政府 经验 新冠肺炎 疫情防控 医疗 合作 援助 捐赠 战胜疫情 分享 交流 专家 感谢 防疫 民众 措施\n",
      "|  #8 (38052) : 物资 企业 生产 口罩 防疫 医疗 保障 武汉 医用 疫情防控 捐赠 复工 防护服 运输 采购 产品 湖北 紧急 防护 供应\n",
      "|  #9 (10243) : 选举 调度 内地 水利部 中下游 水库 发生 特区政府 消防 降雨 流量 超警 浙江 救援 预报 预计 三峡水库 汛情 监测 水文站\n",
      "|  #10 (21624) : 美国 病毒 人权 新冠 媒体 政客 新冠肺炎 美国政府 歧视 世卫 抗疫 科学 美方 联合国 污名化 平等 生命 非洲 种族 危机\n",
      "|  #11 (24992) : 医院 主任 主任医师 书记 党委 党支部 疾病 院长 医学科 预防 街道 重症 感染 公安局 社区 卫生 呼吸 居委会 护士长 党总支\n",
      "|  #12 (43607) : 国家 新冠肺炎 病例 措施 世卫 病毒 确诊 信息 感染 政府 公共卫生 新冠 欧洲 卫生 世界卫生组织 民众 超过 传播 研究 检测\n",
      "|  #13 (39832) : 隔离 口罩 老人 家人 防护服 妻子 回家 孩子 护士 医生 照顾 物资 防护 结束 终于 女儿 手机 休息 春天 家里\n",
      "|  #14 (58384) : 国家 合作 非洲 国际社会 抗疫 抗击疫情 中方 新冠肺炎 公共卫生 人类命运共同体 国际合作 联合国 战胜疫情 发展 携手 中非 理念 团结 分享 峰会\n",
      "|  #15 (46277) : 病例 疫情防控 确诊 措施 北京 健康 重点 检测 国务院 隔离 机制 管理 新冠肺炎 医疗 感染 卫生 风险 国家 救治 联防联控\n",
      "|  #16 (47186) : 患者 医院 医疗队 武汉 重症 救治 新冠肺炎 病人 治疗 医生 方舱 医护人员 病房 收治 病区 医疗 队员 感染 病情 支援\n",
      "|  #17 (33798) : 社区 居民 疫情防控 服务 志愿者 党员 小区 街道 一线 防疫 排查 群众 干部 书记 宣传 村民 信息 基层 消毒 志愿\n",
      "|  #18 (66965) : 疫情防控 发展 经济社会 党中央 群众 部署 打赢 统筹 疫情防控阻击战 形势 精准 保障 能力 决策 科学 措施 增强 湖北 体系 治理\n",
      "|  #19 (42679) : 武汉 一线 党员 湖北 抗疫 医院 医护人员 奋战 新冠肺炎 医务人员 抗击疫情 支援 坚守 疫情防控 军队 火神山医院 英雄 担当 使命 党组织\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PAMClass.TrainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98f4523e9922adb9fa5bc3fbe482da2ccc4d5538d91394c02eecfc3c0d7df7b3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
